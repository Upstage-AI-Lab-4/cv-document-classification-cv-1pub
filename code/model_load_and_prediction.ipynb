{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam,NAdam\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.amp import GradScaler,autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import augraphy\n",
    "from augraphy import AugraphyPipeline, NoiseTexturize,DirtyDrum,InkBleed,LightingGradient,SubtleNoise,BleedThrough, BadPhotoCopy\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 2024\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "# model config\n",
    "model_name = 'efficientnet_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# training config\n",
    "img_size = 300\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "num_workers = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, pipeline = None, transform=None, is_train = True):\n",
    "       # CSV 파일에서 데이터 로드\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.df = self._fix_train_dataframe(self.df).values\n",
    "        self.path = path\n",
    "        self.pipeline = pipeline\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.targets = self._fix_train_dataframe(pd.read_csv(csv))['target'].values\n",
    "        \n",
    "    \n",
    "    def _fix_train_dataframe(self, df):\n",
    "        train_df = df\n",
    "        train_df.loc[train_df['ID'] == '45f0d2dfc7e47c03.jpg', 'target'] = 7  #from 3\n",
    "        train_df.loc[train_df['ID'] == 'aec62dced7af97cd.jpg', 'target'] = 14 #from 3\n",
    "        train_df.loc[train_df['ID'] == '8646f2c3280a4f49.jpg', 'target'] = 3  #from 7\n",
    "        train_df.loc[train_df['ID'] == '1ec14a14bbe633db.jpg', 'target'] = 7  #from 14\n",
    "        return train_df\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.df)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 파일 경로 구성\n",
    " \n",
    "        img_name, label = self.df[idx]\n",
    "        img_path = os.path.join(self.path, img_name)\n",
    "        image = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "        #augraphy\n",
    "        if self.pipeline:\n",
    "            image = self.pipeline(image)\n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']  # 'image=image'로 albumentations 호출\n",
    " \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dataset = ImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    transform=tst_transform,\n",
    "    is_train = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=64,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(load_path, filename, device='cuda'):\n",
    "    \"\"\"\n",
    "    저장된 pkl 파일에서 모델을 불러옵니다.\n",
    "    \n",
    "    Args:\n",
    "        load_path: 불러올 파일이 있는 디렉토리 경로\n",
    "        filename: 불러올 파일 이름\n",
    "        device: 모델을 로드할 디바이스\n",
    "    \n",
    "    Returns:\n",
    "        loaded_model: 불러온 모델\n",
    "    \"\"\"\n",
    "    # 전체 경로\n",
    "    full_path = os.path.join(load_path, filename)\n",
    "    \n",
    "    # pkl 파일 로드\n",
    "    with open(full_path, 'rb') as f:\n",
    "        save_dict = pickle.load(f)\n",
    "    \n",
    "    # 동일한 구조의 모델 생성\n",
    "    model = timm.create_model(\n",
    "        save_dict['model_name'],\n",
    "        pretrained=False,\n",
    "        num_classes=save_dict['num_classes']\n",
    "    )\n",
    "    \n",
    "    # 저장된 가중치 로드\n",
    "    model.load_state_dict(save_dict['state_dict'])\n",
    "    \n",
    "    # 지정된 디바이스로 모델 이동\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model loaded successfully from {full_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df_true, df_pred):\n",
    "    # 'target' 컬럼이 일치하는 행의 개수를 계산\n",
    "    matching_count = (df_true['target'] == df_pred['target']).sum()\n",
    "    # 전체 행 수로 나누어 정확도를 계산\n",
    "    accuracy = matching_count / len(df_true)\n",
    "    return accuracy\n",
    "human_answer_df = pd.read_csv(os.path.join(data_path, 'human_answer.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTimeAugmentation:\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.base_transform = A.Compose([\n",
    "            A.Resize(height=img_size, width=img_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        self.kernel = np.array([\n",
    "                [0, -1, 0],\n",
    "                [-1, 5, -1],\n",
    "                [0, -1, 0]\n",
    "            ])\n",
    "        # 기존 코드의 transform들을 활용\n",
    "        \n",
    "    def denoise_and_sharpen(self, img):\n",
    "        \"\"\"노이즈 제거와 샤프닝을 적용하는 메소드\"\"\"\n",
    "        try:\n",
    "            # BGR to RGB (cv2.imread가 BGR로 읽어오므로)\n",
    "            if len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 노이즈 제거            \n",
    "            # 샤프닝\n",
    "            \n",
    "            denoised = cv2.fastNlMeansDenoisingColored(img, None, h=5, templateWindowSize=7, searchWindowSize=13)\n",
    "            sharpened = cv2.filter2D(denoised, -1, self.kernel)\n",
    "            denoised2 = cv2.fastNlMeansDenoisingColored(sharpened, None, h=5, templateWindowSize=7, searchWindowSize=1)\n",
    "            return denoised2\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in denoise_and_sharpen: {str(e)}\")\n",
    "            print(f\"Image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "            return img\n",
    "\n",
    "    def predict_with_tta(self, dataset, loader):\n",
    "        predictions = []\n",
    "        image_ids = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, _) in enumerate(tqdm(loader, desc=\"TTA Inference\")):\n",
    "                batch_predictions = []\n",
    "                \n",
    "                # 현재 배치의 이미지 ID 저장\n",
    "                start_idx = batch_idx * loader.batch_size\n",
    "                end_idx = min((batch_idx + 1) * loader.batch_size, len(dataset))\n",
    "                batch_image_ids = [dataset.df[i][0] for i in range(start_idx, end_idx)]\n",
    "                image_ids.extend(batch_image_ids)\n",
    "                \n",
    "                # 1. 원본 이미지 예측\n",
    "                imgs_gpu = images.to(self.device)\n",
    "                outputs = self.model(imgs_gpu)\n",
    "                batch_predictions.append(outputs.softmax(dim=1))\n",
    "                \n",
    "                # 2. 노이즈 제거 + 샤프닝 버전\n",
    "                denoised_sharpened_batch = []\n",
    "                for idx in range(start_idx, end_idx):\n",
    "                    # 원본 이미지 다시 로드\n",
    "                    img_name = dataset.df[idx][0]\n",
    "                    img_path = os.path.join(dataset.path, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    \n",
    "                    # 노이즈 제거 및 샤프닝 적용\n",
    "                    processed = self.denoise_and_sharpen(img)\n",
    "                    # transform 적용\n",
    "                    tensor_img = self.base_transform(image=processed)['image']\n",
    "                    denoised_sharpened_batch.append(tensor_img)\n",
    "                \n",
    "                if denoised_sharpened_batch:  # 배치가 비어있지 않은 경우만\n",
    "                    denoised_sharpened_batch = torch.stack(denoised_sharpened_batch).to(self.device)\n",
    "                    outputs = self.model(denoised_sharpened_batch)\n",
    "                    batch_predictions.append(outputs.softmax(dim=1))\n",
    "                \n",
    "                # 모든 예측값의 평균 계산\n",
    "                batch_predictions = torch.stack(batch_predictions)\n",
    "                avg_predictions = batch_predictions.mean(dim=0)\n",
    "                predictions.extend(avg_predictions.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        return predictions, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_with_tta(model, dataset, loader, device):\n",
    "    tta = TestTimeAugmentation(model, device)\n",
    "    predictions, image_ids = tta.predict_with_tta(dataset, loader)\n",
    "    \n",
    "    # 결과를 DataFrame으로 변환\n",
    "    pred_df = pd.DataFrame({\n",
    "        'ID': image_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../output/models'\n",
    "#output/night_sample/current_epoch_model_14.pkl\n",
    "model = load_model(model_path, 'model_name','cuda')\n",
    "\n",
    "model.eval()\n",
    "# TTA 추론 실행\n",
    "#pred_df_from_tta = run_inference_with_tta(model, tst_dataset, tst_loader, device)\n",
    "preds_list = []\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('../output/output/pred_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
